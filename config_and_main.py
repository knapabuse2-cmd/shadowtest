# config_and_main.py - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø

import asyncio
import time
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import numpy as np
from bias_detector import ICTBiasDetector, BiasContext, MarketBias
from data.binance_source import BinanceDataSource
from output_module import TelegramSignalPublisher
from output_log_publisher import TelegramLogPublisher
from core_orchestrator import Orchestrator
from breaker_detector import BreakerDetector
from mitigation_block_detector import MitigationBlockDetector
from imbalance_detector import ImbalanceDetector
from liquidity_detector import LiquidityDetector

from analysis_detectors import (
    OrderBlockDetector,
    FairValueGapDetector,
    FractalDetector,
    VolumeContextBuilder,
    detect_market_structure
)
from killzone_detector import KillzoneDetector
from idm_detector import IDMDetector

from analysis_chains import (
    Chain_1_1,
    Chain_1_2,
    Chain_1_3,
    Chain_1_4,
    Chain_1_5,
    Chain_3_2,
    Signal_1,
    Chain_2_6
)

from position_tracker import PositionTracker
from signal_validator import SignalValidator
from signal_deduplicator import SignalDeduplicator
from analysis_interfaces import ChainSignal, Zone, DetectionResult

# --------------------------
#  –ù–ê–°–¢–†–û–ô–ö–ò
# --------------------------
from config import (
       BOT_TOKEN,
       CHAT_ID,
       LOG_CHAT_ID,
       SYMBOLS,
       TIMEFRAMES,
       LOOP_INTERVAL,
       POSITION_CLEANUP_INTERVAL,
       MIN_CONFLUENCE_SCORE,
       PERFORMANCE_DATA_FILE,
       CORRELATION_UPDATE_INTERVAL
   )


# ================================
#   ENHANCED ORCHESTRATOR
# ================================

class EnhancedOrchestrator(Orchestrator):
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π Orchestrator, –∫–æ—Ç–æ—Ä—ã–π —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç detections
    """

    def __init__(self, data_source, detectors: dict, chains: list):
        super().__init__(data_source, detectors, chains)
        self.last_detections = {}  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ detections
        self.last_candles = {}  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ candles

    async def analyze_symbol_with_data(self, symbol: str):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–º–≤–æ–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç signals + detections + candles
        –° –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ú BIAS DETECTOR
        """
        timeframes = ["1d", "4h", "1h", "15m"]

        await self._log(f"üîç Analyzing {symbol}", "INFO")

        # --------------------------------------------------------
        # LOAD CANDLES
        # --------------------------------------------------------
        candles = {}
        failed_tfs = []

        for tf in timeframes:
            try:
                data = await self.data_source.get_ohlcv(symbol, tf, limit=300)
                if data is None:
                    data = []
                candles[tf] = data

                if len(data) == 0:
                    failed_tfs.append(tf)

            except Exception as e:
                await self._log(f"‚ùå Failed {symbol} {tf}: {e}", "ERROR")
                candles[tf] = []

        if failed_tfs:
            await self._log(f"‚ö†Ô∏è {symbol}: No data for {', '.join(failed_tfs)}", "WARNING")

        # --------------------------------------------------------
        # RUN DETECTORS
        # --------------------------------------------------------
        detections = {}
        total_zones = 0

        for tf in timeframes:
            if tf not in candles or len(candles[tf]) == 0:
                detections[tf] = DetectionResult([], None)
                continue

            det_results = []

            for name, detector in self.detectors.items():
                try:
                    if candles[tf] is None or len(candles[tf]) == 0:
                        continue

                    result = detector.detect(candles[tf], tf)
                    if isinstance(result, DetectionResult):
                        det_results.append(result)

                except Exception as e:
                    await self._log(f"‚ùå Detector {name} failed on {symbol}: {e}", "ERROR")

            # Merge results
            merged_zones = []
            merged_context = None

            for r in det_results:
                if r.zones:
                    merged_zones.extend(r.zones)
                if r.context is not None:
                    merged_context = r.context

            detections[tf] = DetectionResult(merged_zones, merged_context)
            total_zones += len(merged_zones)

        if total_zones > 0:
            await self._log(f"‚úì {symbol}: Found {total_zones} zones total", "INFO")

        # --------------------------------------------------------
        # –ù–û–í–û–ï: –ê–ù–ê–õ–ò–ó BIAS –î–õ–Ø –ö–ê–ñ–î–û–ì–û –¢–ê–ô–ú–§–†–ï–ô–ú–ê
        # --------------------------------------------------------

        bias_detector = ICTBiasDetector()
        bias_contexts = {}

        # Mapping –¥–ª—è —Å—Ç–∞—Ä—à–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        htf_map = {
            "15m": "1h",
            "1h": "4h",
            "4h": "1d",
            "1d": None
        }

        for tf in timeframes:
            if tf not in candles or len(candles[tf]) < 50:
                continue

            try:
                # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ä—à–∏–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
                htf = htf_map.get(tf)
                htf_candles = candles.get(htf) if htf else None

                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º bias
                bias_context = bias_detector.detect_comprehensive_bias(
                    candles_current=candles[tf],
                    candles_htf=htf_candles,
                    zones_current=detections[tf].zones if tf in detections else None,
                    tf_current=tf,
                    tf_htf=htf if htf else "4h"
                )

                bias_contexts[tf] = bias_context

                # –õ–æ–≥–∏—Ä—É–µ–º bias –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                await self._log(
                    f"üìä {symbol} {tf} BIAS: {bias_context.bias} "
                    f"(strength: {bias_context.strength:.0f}, "
                    f"P/D: {bias_context.premium_discount})",
                    "DEBUG"
                )

            except Exception as e:
                await self._log(f"‚ö†Ô∏è Bias detector failed for {symbol} {tf}: {e}", "DEBUG")
                # –°–æ–∑–¥–∞–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π bias –∫–∞–∫ fallback
                from bias_detector import BiasContext, MarketBias
                bias_contexts[tf] = BiasContext(
                    bias=MarketBias.NEUTRAL,
                    htf_bias=None,
                    structure_break=None,
                    premium_discount="EQUILIBRIUM",
                    order_flow="NEUTRAL_OF",
                    strength=50.0,
                    key_levels={},
                    notes=["Bias detection failed"]
                )

        # --------------------------------------------------------
        # RUN CHAINS –° BIAS CONTEXTS
        # --------------------------------------------------------
        from analysis_interfaces import ChainContext

        ctx = ChainContext(
            symbol=symbol,
            candles=candles,
            detections=detections,
            bias_contexts=bias_contexts,
            # –î–û–ë–ê–í–õ–ï–ù–û: –ø–µ—Ä–µ–¥–∞–µ–º bias contexts
            log_callback=None if not self.verbose_logging else self.log_callback,
        )

        all_signals = []

        for chain in self.chains:
            try:
                res = await chain.analyze(ctx)
                if res:
                    all_signals.extend(res)

            except Exception as e:
                await self._log(f"‚ùå Chain {chain.chain_id} failed: {e}", "ERROR")

        if all_signals:
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ bias –≤ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤
            for sig in all_signals:
                if sig.tf in bias_contexts:
                    bias = bias_contexts[sig.tf]
                    sig.description += f" | Bias: {bias.bias} ({bias.strength:.0f})"

            await self._log(
                f"üéØ {symbol}: {len(all_signals)} signals " +
                f"({', '.join([s.chain_id for s in all_signals])})",
                "INFO"
            )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        self.last_detections[symbol] = detections
        self.last_candles[symbol] = candles
        self.last_bias_contexts = bias_contexts  # –ù–û–í–û–ï: —Å–æ—Ö—Ä–∞–Ω—è–µ–º bias

        return all_signals, detections, candles


# ================================
#   CONFLUENCE ANALYZER
# ================================

@dataclass
class ConfluenceScore:
    symbol: str
    zone: Zone
    score: float  # 0-100
    timeframes_aligned: List[str]
    supporting_factors: List[str]


class ConfluenceAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∑–æ–Ω –Ω–∞ —Ä–∞–∑–Ω—ã—Ö TF
    """

    def analyze_confluence(
            self,
            symbol: str,
            detections: Dict[str, DetectionResult],
            candles: Dict[str, List]
    ) -> List[ConfluenceScore]:

        confluence_zones = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –∑–æ–Ω—É –Ω–∞ –º–ª–∞–¥—à–µ–º TF
        zones_15m = detections.get("15m", DetectionResult([], None)).zones
        if not zones_15m:
            return []

        for zone_15m in zones_15m:
            score = 0
            aligned_tfs = ["15m"]
            factors = []

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —Å –∑–æ–Ω–∞–º–∏ —Å—Ç–∞—Ä—à–∏—Ö TF
            for tf in ["1h", "4h", "1d"]:
                if tf not in detections:
                    continue

                for zone_htf in detections[tf].zones:
                    if self._zones_overlap(zone_15m, zone_htf):
                        score += 25  # +25 –∑–∞ –∫–∞–∂–¥—ã–π TF
                        aligned_tfs.append(tf)
                        factors.append(f"{tf} {zone_htf.type}")

                        # Bonus –∑–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ç–∏–ø –∑–æ–Ω—ã
                        if zone_15m.type == zone_htf.type:
                            score += 10
                            factors.append(f"Type match on {tf}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —É—Ä–æ–≤–Ω–µ–π
            if "15m" in candles and candles["15m"]:
                current_price = candles["15m"][-1].close

                # –ó–æ–Ω–∞ —É round number
                if self._near_round_number(zone_15m):
                    score += 15
                    factors.append("Round number")

                # –ó–æ–Ω–∞ —É –¥–Ω–µ–≤–Ω–æ–≥–æ high/low
                if "1d" in candles and candles["1d"]:
                    daily_high = max(c.high for c in candles["1d"][-1:])
                    daily_low = min(c.low for c in candles["1d"][-1:])

                    if abs(zone_15m.high - daily_high) / daily_high < 0.001:
                        score += 20
                        factors.append("Daily high")
                    elif abs(zone_15m.low - daily_low) / daily_low < 0.001:
                        score += 20
                        factors.append("Daily low")

            if score >= MIN_CONFLUENCE_SCORE:
                confluence_zones.append(
                    ConfluenceScore(
                        symbol=symbol,
                        zone=zone_15m,
                        score=min(100, score),
                        timeframes_aligned=aligned_tfs,
                        supporting_factors=factors
                    )
                )

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score
        return sorted(confluence_zones, key=lambda x: x.score, reverse=True)

    def _zones_overlap(self, z1: Zone, z2: Zone, tolerance: float = 0.001) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –∑–æ–Ω —Å –¥–æ–ø—É—Å–∫–æ–º"""
        z1_expanded_high = z1.high * (1 + tolerance)
        z1_expanded_low = z1.low * (1 - tolerance)

        return not (z1_expanded_high < z2.low or z1_expanded_low > z2.high)

    def _near_round_number(self, zone: Zone) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–∏–∑–æ—Å—Ç–∏ –∫ –∫—Ä—É–≥–ª—ã–º —á–∏—Å–ª–∞–º"""
        for price in [zone.high, zone.low]:
            # –î–ª—è –∫—Ä–∏–ø—Ç—ã –∫—Ä—É–≥–ª—ã–µ —á–∏—Å–ª–∞
            if price > 1000:
                if price % 1000 < 50 or price % 1000 > 950:
                    return True
            elif price > 100:
                if price % 100 < 5 or price % 100 > 95:
                    return True
            elif price > 10:
                if price % 10 < 0.5 or price % 10 > 9.5:
                    return True
        return False


# ================================
#   PERFORMANCE OPTIMIZER
# ================================

class PerformanceOptimizer:
    """
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π —Ü–µ–ø–æ—á–∫–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    """

    def __init__(self, data_file: str = PERFORMANCE_DATA_FILE):
        self.data_file = data_file
        self.performance_data = self._load_data()
        self.min_samples = 30  # –ú–∏–Ω–∏–º—É–º —Å–¥–µ–ª–æ–∫ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏

    def _load_data(self) -> Dict:
        try:
            with open(self.data_file, 'r') as f:
                return json.load(f)
        except:
            return {}

    def _save_data(self):
        try:
            with open(self.data_file, 'w') as f:
                json.dump(self.performance_data, f, indent=2)
        except Exception as e:
            print(f"Error saving performance data: {e}")

    def update_signal_result(
            self,
            chain_id: str,
            symbol: str,
            tf: str,
            outcome: str,  # "TP", "SL", "BE"
            rr_achieved: float,
            entry_time: datetime = None
    ):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏
        """
        if entry_time is None:
            entry_time = datetime.now()

        key = f"{chain_id}_{symbol}"

        if key not in self.performance_data:
            self.performance_data[key] = {
                "signals": [],
                "stats": {}
            }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        self.performance_data[key]["signals"].append({
            "timestamp": entry_time.isoformat(),
            "tf": tf,
            "outcome": outcome,
            "rr_achieved": rr_achieved,
            "hour": entry_time.hour,
            "day_of_week": entry_time.weekday()
        })

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 500 —Å–∏–≥–Ω–∞–ª–∞–º–∏
        if len(self.performance_data[key]["signals"]) > 500:
            self.performance_data[key]["signals"] = self.performance_data[key]["signals"][-500:]

        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._recalculate_stats(key)
        self._save_data()

    def _recalculate_stats(self, key: str):
        """
        –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è —Ü–µ–ø–æ—á–∫–∏
        """
        signals = self.performance_data[key]["signals"]

        if len(signals) < 10:
            return

        # Win rate
        wins = sum(1 for s in signals if s["outcome"] == "TP")
        win_rate = wins / len(signals) if signals else 0

        # –°—Ä–µ–¥–Ω–∏–π RR
        rr_values = [s["rr_achieved"] for s in signals if s["rr_achieved"] is not None]
        avg_rr = sum(rr_values) / len(rr_values) if rr_values else 0

        # –õ—É—á—à–∏–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
        tf_performance = {}
        for s in signals:
            tf = s["tf"]
            if tf not in tf_performance:
                tf_performance[tf] = {"wins": 0, "total": 0}
            tf_performance[tf]["total"] += 1
            if s["outcome"] == "TP":
                tf_performance[tf]["wins"] += 1

        best_tf = "15m"  # default
        if tf_performance:
            best_tf = max(
                tf_performance.items(),
                key=lambda x: x[1]["wins"] / x[1]["total"] if x[1]["total"] > 5 else 0
            )[0]

        # –õ—É—á—à–µ–µ –≤—Ä–µ–º—è —Å—É—Ç–æ–∫
        hour_performance = {}
        for s in signals:
            hour = s.get("hour", 0)
            if hour not in hour_performance:
                hour_performance[hour] = {"wins": 0, "total": 0}
            hour_performance[hour]["total"] += 1
            if s["outcome"] == "TP":
                hour_performance[hour]["wins"] += 1

        best_hours = []
        if hour_performance:
            best_hours = sorted(
                hour_performance.items(),
                key=lambda x: x[1]["wins"] / x[1]["total"] if x[1]["total"] > 3 else 0,
                reverse=True
            )[:3]  # Top 3 —á–∞—Å–∞
            best_hours = [h[0] for h in best_hours]

        self.performance_data[key]["stats"] = {
            "win_rate": win_rate,
            "avg_rr": avg_rr,
            "best_tf": best_tf,
            "best_hours": best_hours,
            "total_signals": len(signals)
        }

    def should_take_signal(
            self,
            chain_id: str,
            symbol: str,
            tf: str,
            current_time: datetime = None
    ) -> Tuple[bool, str]:
        """
        –†–µ—à–∞–µ—Ç, —Å—Ç–æ–∏—Ç –ª–∏ –±—Ä–∞—Ç—å —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        """
        key = f"{chain_id}_{symbol}"

        if key not in self.performance_data:
            return True, "No history"

        stats = self.performance_data[key].get("stats", {})

        if not stats or stats.get("total_signals", 0) < self.min_samples:
            return True, "Insufficient data"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º win rate
        if stats["win_rate"] < 0.30:  # –ú–µ–Ω—å—à–µ 30% - –æ—Ç–∫–ª—é—á–∞–µ–º
            return False, f"Low win rate: {stats['win_rate']:.1%}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–µ–¥–Ω–∏–π RR
        if stats.get("avg_rr",
                     0) < -0.5:  # –°—Ä–µ–¥–Ω–∏–π —É–±—ã—Ç–æ–∫ –±–æ–ª—å—à–µ 0.5R
            return False, f"Negative avg RR: {stats['avg_rr']:.2f}"

        return True, "OK"

    def get_chain_ranking(self) -> List[Tuple[str, float]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ —Ü–µ–ø–æ—á–µ–∫ –ø–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        """
        rankings = []

        for key, data in self.performance_data.items():
            stats = data.get("stats", {})
            if stats and stats.get("total_signals", 0) >= 20:
                # –§–æ—Ä–º—É–ª–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: win_rate * avg_rr
                score = stats["win_rate"] * max(stats.get("avg_rr", 0), 0)
                chain_id = key.split("_")[0]
                rankings.append((chain_id, score))

        return sorted(rankings, key=lambda x: x[1], reverse=True)


# ================================
#   CORRELATION ANALYZER
# ================================

class CorrelationAnalyzer:
    """
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –º–µ–∂–¥—É —Å–∏–º–≤–æ–ª–∞–º–∏
    """

    def __init__(self):
        self.correlation_matrix = {}
        self.last_update = None

    def calculate_correlations(
            self,
            symbols: List[str],
            data_source
    ) -> None:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        """
        # –•–∞—Ä–¥–∫–æ–¥ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç
        known_correlations = {
            "BTC/USDT_ETH/USDT": 0.85,
            "ETH/USDT_BTC/USDT": 0.85,
            "BNB/USDT_ETH/USDT": 0.75,
            "ETH/USDT_BNB/USDT": 0.75,
            "SOL/USDT_AVAX/USDT": 0.70,
            "AVAX/USDT_SOL/USDT": 0.70,
            "DOT/USDT_ATOM/USDT": 0.65,
            "ATOM/USDT_DOT/USDT": 0.65,
        }

        self.correlation_matrix = known_correlations
        self.last_update = datetime.now()

    def check_correlation_conflict(
            self,
            new_signal: ChainSignal,
            active_signals: List[ChainSignal]
    ) -> Tuple[bool, str]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç —Å –∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏ –Ω–∞ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏—Ö –ø–∞—Ä–∞—Ö
        """
        for active in active_signals:
            if active.symbol == new_signal.symbol:
                continue

            key = f"{new_signal.symbol}_{active.symbol}"
            corr = self.correlation_matrix.get(key, 0)

            # –í—ã—Å–æ–∫–∞—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
            if corr > 0.7:
                # –°–∏–≥–Ω–∞–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –æ–¥–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏
                if new_signal.direction != active.direction:
                    return True, f"Correlation conflict with {active.symbol}"

            # –í—ã—Å–æ–∫–∞—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
            elif corr < -0.7:
                # –°–∏–≥–Ω–∞–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö
                if new_signal.direction == active.direction:
                    return True, f"Inverse correlation conflict with {active.symbol}"

        return False, "OK"


# ================================
#   ADVANCED SIGNAL FILTER
# ================================

class AdvancedSignalFilter:
    """
    –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
    """

    def __init__(self):
        pass

    def filter_by_zone_age(
            self,
            signal: ChainSignal,
            zones: List[Zone],
            candles: List
    ) -> Tuple[bool, str]:
        """
        –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–∞ –∑–æ–Ω —Å —É—á–µ—Ç–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        """
        if not candles:
            return True, "OK"

        current_candle_index = len(candles)

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –†–∞–∑–Ω—ã–µ –ª–∏–º–∏—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç –∑–æ–Ω—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç TF
        tf_age_limits = {
            "15m": 200,  # 200 —Å–≤–µ—á–µ–π = ~50 —á–∞—Å–æ–≤
            "30m": 150,  # 150 —Å–≤–µ—á–µ–π = ~75 —á–∞—Å–æ–≤
            "1h": 120,  # 120 —Å–≤–µ—á–µ–π = 5 –¥–Ω–µ–π
            "4h": 100,  # 100 —Å–≤–µ—á–µ–π = ~16 –¥–Ω–µ–π
            "1d": 50,  # 50 —Å–≤–µ—á–µ–π = 50 –¥–Ω–µ–π
        }

        # –ë–µ—Ä–µ–º –ª–∏–º–∏—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ TF —Å–∏–≥–Ω–∞–ª–∞
        max_age = tf_age_limits.get(signal.tf, 100)

        for zone in zones:
            if hasattr(zone, 'candle_index') and zone.candle_index:
                age = current_candle_index - zone.candle_index

                # –ù–û–í–û–ï: –£—á–∏—Ç—ã–≤–∞–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º —Å–∞–º–æ–π –∑–æ–Ω—ã
                if hasattr(zone, 'tf') and zone.tf:
                    # –ï—Å–ª–∏ –∑–æ–Ω–∞ —Å–æ —Å—Ç–∞—Ä—à–µ–≥–æ TF, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ–ø—É—Å—Ç–∏–º—ã–π –≤–æ–∑—Ä–∞—Å—Ç
                    zone_tf_limit = tf_age_limits.get(zone.tf, 100)

                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–∏–π –∏–∑ –¥–≤—É—Ö –ª–∏–º–∏—Ç–æ–≤
                    effective_limit = max(max_age, zone_tf_limit)

                    # –î–ª—è –∑–æ–Ω —Å—Ç–∞—Ä—à–∏—Ö TF –ø—Ä–∏–º–µ–Ω—è–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å
                    if zone.tf in ["4h", "1d"]:
                        effective_limit = effective_limit * 1.5  # +50% –¥–ª—è —Å—Ç–∞—Ä—à–∏—Ö TF

                    if age > effective_limit:
                        return False, f"Zone too old ({age} candles > {effective_limit} limit for {zone.tf})"
                else:
                    # Fallback –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É
                    if age > max_age:
                        return False, f"Zone too old ({age} candles > {max_age} limit)"

        return True, "OK"

    def filter_by_momentum(
            self,
            signal: ChainSignal,
            candles: List
    ) -> Tuple[bool, str]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–º–ø—É–ª—å—Å –¥–≤–∏–∂–µ–Ω–∏—è (–ø—Ä–æ—Å—Ç–æ–π RSI)
        """
        if not candles or len(candles) < 20:
            return True, "OK"

        # RSI calculation
        gains = []
        losses = []

        for i in range(1, min(15, len(candles))):
            if i >= len(candles):
                break
            change = candles[-i].close - candles[-i - 1].close
            if change > 0:
                gains.append(change)
            else:
                losses.append(abs(change))

        if not gains and not losses:
            return True, "OK"

        avg_gain = sum(gains) / len(gains) if gains else 0
        avg_loss = sum(losses) / len(losses) if losses else 1e-10

        if avg_loss == 0:
            rsi = 100
        else:
            rs = avg_gain / avg_loss
            rsi = 100 - (100 / (1 + rs))

        # –§–∏–ª—å—Ç—Ä—É–µ–º —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        direction = str(signal.direction).upper()
        if "LONG" in direction and rsi > 75:
            return False, f"Overbought (RSI={rsi:.0f})"
        if "SHORT" in direction and rsi < 25:
            return False, f"Oversold (RSI={rsi:.0f})"

        return True, "OK"

    def filter_by_volatility(
            self,
            signal: ChainSignal,
            candles: List
    ) -> Tuple[bool, str]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (ATR)
        """
        if not candles or len(candles) < 20:
            return True, "OK"

        # –ü—Ä–æ—Å—Ç–æ–π ATR
        trs = []
        for i in range(1, min(14, len(candles))):
            h = candles[-i].high
            l = candles[-i].low
            prev_close = candles[-i - 1].close
            tr = max(h - l, abs(h - prev_close), abs(l - prev_close))
            trs.append(tr)

        if not trs:
            return True, "OK"

        atr = sum(trs) / len(trs)
        current_price = candles[-1].close
        atr_percent = (atr / current_price) * 100

        # –°–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        if atr_percent < 0.5:
            return False, f"Low volatility (ATR={atr_percent:.2f}%)"

        # –°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        if atr_percent > 5:
            return False, f"High volatility (ATR={atr_percent:.2f}%)"

        return True, "OK"


# ================================
#   HEARTBEAT
# ================================

async def heartbeat(log):
    while True:
        await log("üíì Heartbeat ‚Äì bot alive", to_telegram=False)
        await asyncio.sleep(300)  # –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç


# ================================
#   –ì–õ–ê–í–ù–ê–Ø –ü–†–û–ì–†–ê–ú–ú–ê
# ================================

async def main():
    print("üöÄ Starting Smart Money bot (FIXED VERSION)")

    # –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö
    source = BinanceDataSource()

    # –ü–∞–±–ª–∏—à–µ—Ä—ã
    signal_publisher = TelegramSignalPublisher(BOT_TOKEN, CHAT_ID)
    log_publisher = TelegramLogPublisher(BOT_TOKEN, LOG_CHAT_ID)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
    await signal_publisher.init_pinned_message()

    # –¢—Ä–µ–∫–µ—Ä –ø–æ–∑–∏—Ü–∏–π
    position_tracker = PositionTracker(publisher=signal_publisher)
    position_tracker.debug_mode = False

    # –í–∞–ª–∏–¥–∞—Ç–æ—Ä —Å–∏–≥–Ω–∞–ª–æ–≤
    validator = SignalValidator()

    # –ù–û–í–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´
    confluence_analyzer = ConfluenceAnalyzer()
    performance_optimizer = PerformanceOptimizer()
    correlation_analyzer = CorrelationAnalyzer()
    advanced_filter = AdvancedSignalFilter()

    # –§—É–Ω–∫—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    async def log(msg: str, to_telegram: bool = False):
        print(msg)
        if to_telegram:
            try:
                await log_publisher.send_log(msg)
            except:
                pass

    # –ó–∞–ø—É—Å–∫ heartbeat
    asyncio.create_task(heartbeat(log))

    # –î–µ—Ç–µ–∫—Ç–æ—Ä—ã
    detectors = {
        "OrderBlock": OrderBlockDetector(),
        "FairValueGap": FairValueGapDetector(),
        "Fractal": FractalDetector(),
        "VolumeContext": VolumeContextBuilder(),
        "IDM": IDMDetector(),
    }

    # –¶–µ–ø–æ—á–∫–∏
    chains = [
        Chain_1_1(),
        Chain_1_2(),
        Chain_1_3(),
        Chain_1_4(),
        Chain_1_5(),
        Chain_3_2(),
        Signal_1(),
        Chain_2_6()
    ]

    # –ò–°–ü–û–õ–¨–ó–£–ï–ú –†–ê–°–®–ò–†–ï–ù–ù–´–ô ORCHESTRATOR
    orchestrator = EnhancedOrchestrator(source, detectors, chains)
    orchestrator.set_logger(log, verbose=False)

    # –ö–µ—à–∏ –∏ —Å—á–µ—Ç—á–∏–∫–∏
    deduplicator = SignalDeduplicator()  # –£–º–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
    active_signals_per_symbol = {}
    cycle_count = 0

    # –ó–ê–©–ò–¢–ê –û–¢ –î–£–ë–õ–ò–†–û–í–ê–ù–ò–Ø –°–ò–ì–ù–ê–õ–û–í
    last_signal_time = {}  # {symbol-direction: timestamp} –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è —á–∞—Å—Ç–æ—Ç—ã
    MIN_SIGNAL_INTERVAL = 300000  # 5 –º–∏–Ω—É—Ç –º–µ–∂–¥—É —Å–∏–≥–Ω–∞–ª–∞–º–∏ –≤ –æ–¥–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏
    MAX_SIGNALS_PER_SYMBOL = 2  # –ú–∞–∫—Å–∏–º—É–º 2 –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ —Å–∏–º–≤–æ–ª
    signal_count_per_symbol = {}  # {symbol: count} —Å—á–µ—Ç—á–∏–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤

    # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π)
    all_active_signals = []

    try:
        while True:
            start = time.time()
            cycle_count += 1

            print("\n" + "=" * 50)
            print(f"üîé SCAN CYCLE #{cycle_count} STARTED")
            print("=" * 50)

            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏
            if cycle_count % CORRELATION_UPDATE_INTERVAL == 1:
                print("üìä Updating correlations...")
                correlation_analyzer.calculate_correlations(SYMBOLS, source)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω–æ–µ
            if cycle_count % 10 == 1:
                await log(f"üîé Cycle #{cycle_count} started", to_telegram=True)

            # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            total_signals = 0
            validated_signals = 0
            confluence_filtered = 0
            performance_filtered = 0
            signals_by_chain = {}

            for index, symbol in enumerate(SYMBOLS):
                print(f"\n[{index + 1}/{len(SYMBOLS)}] Scanning {symbol}...")
                t0 = time.time()

                # ---------------------------------------
                # 1) –ê–ù–ê–õ–ò–ó –°–ò–ì–ù–ê–õ–û–í –° –ü–û–õ–£–ß–ï–ù–ò–ï–ú –î–ê–ù–ù–´–•
                # ---------------------------------------
                try:
                    # –ò–°–ü–û–õ–¨–ó–£–ï–ú –ù–û–í–´–ô –ú–ï–¢–û–î
                    signals, detections, candles_dict = await orchestrator.analyze_symbol_with_data(symbol)

                    if signals:
                        print(f"  ‚Üí Found {len(signals)} raw signals")
                        total_signals += len(signals)

                        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                        contexts = {}
                        for tf in TIMEFRAMES:
                            if tf in candles_dict and candles_dict[tf] and len(candles_dict[tf]) > 10:
                                contexts[tf] = detect_market_structure(candles_dict[tf], tf)

                        # ---------------------------------------
                        # 2) –í–ê–õ–ò–î–ê–¶–ò–Ø –°–ò–ì–ù–ê–õ–û–í
                        # ---------------------------------------
                        valid_signals = validator.filter_signals(signals, contexts)
                        validated_signals += len(valid_signals)

                        if valid_signals:
                            print(f"  ‚úî {len(valid_signals)} signals passed validation")

                            # –°—á–∏—Ç–∞–µ–º –ø–æ —Ü–µ–ø–æ—á–∫–∞–º
                            for sig in valid_signals:
                                if sig.chain_id not in signals_by_chain:
                                    signals_by_chain[sig.chain_id] = 0
                                signals_by_chain[sig.chain_id] += 1
                        else:
                            print(f"  √¢≈°¬† All signals filtered out")

                        signals = valid_signals

                        # ---------------------------------------
                        # 3) –ê–ù–ê–õ–ò–ó –ö–û–ù–§–õ–Æ–ï–ù–¶–ò–ò (–¢–ï–ü–ï–†–¨ –†–ê–ë–û–¢–ê–ï–¢)
                        # ---------------------------------------
                        if signals and detections:  # –¢–µ–ø–µ—Ä—å —É –Ω–∞—Å –µ—Å—Ç—å detections!
                            print(f"  üîç Analyzing confluence...")
                            confluence_scores = confluence_analyzer.analyze_confluence(
                                symbol=symbol,
                                detections=detections,
                                candles=candles_dict
                            )

                            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫–æ–Ω—Ñ–ª—é–µ–Ω—Ü–∏–∏
                            if confluence_scores:
                                print(f"    Found {len(confluence_scores)} confluence zones")
                                high_confluence_zones = [c.zone for c in confluence_scores if
                                                         c.score >= MIN_CONFLUENCE_SCORE]

                                if high_confluence_zones:
                                    print(
                                        f"    {len(high_confluence_zones)} zones with score >= {MIN_CONFLUENCE_SCORE}")

                                filtered_by_confluence = []
                                for sig in signals:
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å–∏–≥–Ω–∞–ª –≤ –∑–æ–Ω–µ —Å –≤—ã—Å–æ–∫–æ–π –∫–æ–Ω—Ñ–ª—é–µ–Ω—Ü–∏–µ–π
                                    sig_in_confluence = False
                                    for zone in high_confluence_zones:
                                        if zone.low <= sig.entry <= zone.high:
                                            sig_in_confluence = True
                                            break

                                    if sig_in_confluence:
                                        filtered_by_confluence.append(sig)
                                    else:
                                        confluence_filtered += 1
                                        print(f"    ‚úó {sig.chain_id} - low confluence")

                                signals = filtered_by_confluence

                        # ---------------------------------------
                        # 4) –ü–†–û–í–ï–†–ö–ê –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò
                        # ---------------------------------------
                        if signals:
                            performance_checked = []
                            for sig in signals:
                                should_take, reason = performance_optimizer.should_take_signal(
                                    chain_id=sig.chain_id,
                                    symbol=sig.symbol,
                                    tf=sig.tf,
                                    current_time=datetime.now()
                                )

                                if should_take:
                                    performance_checked.append(sig)
                                else:
                                    performance_filtered += 1
                                    print(f"    ‚úó {sig.chain_id} - {reason}")

                            signals = performance_checked

                        # ---------------------------------------
                        # 5) –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø
                        # ---------------------------------------
                        if signals and candles_dict.get(sig.tf):
                            advanced_filtered = []
                            for sig in signals:
                                # –ü–æ–ª—É—á–∞–µ–º –∑–æ–Ω—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ TF
                                current_zones = detections.get(sig.tf, DetectionResult([], None)).zones

                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–∞ –∑–æ–Ω
                                passed, reason = advanced_filter.filter_by_zone_age(
                                    sig,
                                    current_zones,
                                    candles_dict.get(sig.tf, [])
                                )
                                if not passed:
                                    print(f"    ‚úó {sig.chain_id} - {reason}")
                                    continue

                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ momentum
                                passed, reason = advanced_filter.filter_by_momentum(
                                    sig,
                                    candles_dict.get(sig.tf, [])
                                )
                                if not passed:
                                    print(f"    ‚úó {sig.chain_id} - {reason}")
                                    continue

                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
                                passed, reason = advanced_filter.filter_by_volatility(
                                    sig,
                                    candles_dict.get(sig.tf, [])
                                )
                                if not passed:
                                    print(f"    ‚úó {sig.chain_id} - {reason}")
                                    continue

                                advanced_filtered.append(sig)

                            signals = advanced_filtered

                        # ---------------------------------------
                        # 6) –ü–†–û–í–ï–†–ö–ê –ö–û–†–†–ï–õ–Ø–¶–ò–ô
                        # ---------------------------------------
                        if signals and all_active_signals:
                            correlation_filtered = []
                            for sig in signals:
                                has_conflict, reason = correlation_analyzer.check_correlation_conflict(
                                    sig, all_active_signals
                                )

                                if not has_conflict:
                                    correlation_filtered.append(sig)
                                else:
                                    print(f"    ‚úó {sig.chain_id} - {reason}")

                            signals = correlation_filtered

                    else:
                        print(f"  ‚àÖ No signals found")
                        signals = []

                except Exception as e:
                    print(f"  ‚ùå ERROR: {e}")
                    import traceback
                    print(traceback.format_exc())
                    await log(f"‚ùå Error analyzing {symbol}: {e}", to_telegram=True)
                    signals = []
                    continue

                t1 = time.time()
                print(f"  ‚è± Time: {t1 - t0:.2f} sec")

                now_ms = int(time.time() * 1000)

                # ---------------------------------------
                # 7) –ü–†–û–í–ï–†–ö–ê –ù–ê –ö–û–ù–§–õ–ò–ö–¢–´ –° –ê–ö–¢–ò–í–ù–´–ú–ò –ü–û–ó–ò–¶–ò–Ø–ú–ò
                # ---------------------------------------
                if symbol in active_signals_per_symbol and signals:
                    active_directions = active_signals_per_symbol[symbol]
                    filtered_signals = []

                    for sig in signals:
                        sig_dir = str(sig.direction).upper().replace("DIRECTION.", "")

                        conflict = False
                        for active_dir in active_directions:
                            if (sig_dir in ["LONG", "BUY"] and active_dir in ["SHORT", "SELL"]) or \
                                    (sig_dir in ["SHORT", "SELL"] and active_dir in ["LONG", "BUY"]):
                                print(
                                    f"  √¢≈°¬† Skipping {sig.chain_id} {sig_dir} - active {active_dir} position exists")
                                conflict = True
                                break

                        if not conflict:
                            filtered_signals.append(sig)

                    signals = filtered_signals

                # ---------------------------------------
                # 8) –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ù–û–í–´–• –°–ò–ì–ù–ê–õ–û–í
                # ---------------------------------------
                for s in signals:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç —á–µ—Ä–µ–∑ —É–º–Ω—ã–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ç–æ—Ä
                    is_dup, reason = deduplicator.is_duplicate(s, tf=s.tf)

                    if is_dup:
                        print(f"  üîÅ Duplicate: {reason}")
                        continue

                    print(f"  üì® Sending: {s.chain_id} {s.direction}")
                    try:
                        await signal_publisher.publish(s)
                        deduplicator.register_signal(s, tf=s.tf)
                        position_tracker.register_signal(s, now_ms)
                        all_active_signals.append(s)

                        if symbol not in active_signals_per_symbol:
                            active_signals_per_symbol[symbol] = set()
                        dir_normalized = str(s.direction).upper().replace("DIRECTION.", "")
                        active_signals_per_symbol[symbol].add(dir_normalized)

                        await log(f"üèÅ NEW: {s.symbol} {s.chain_id} {s.direction} RR={s.rr:.1f}", to_telegram=True)
                    except Exception as e:
                        print(f"  √¢≈°¬† Failed: {e}")

                # ---------------------------------------
                # 9) –û–ë–ù–û–í–õ–Ø–ï–ú –°–¢–ê–¢–£–° –ü–û–ó–ò–¶–ò–ô
                # ---------------------------------------
                try:
                    candles_15m = await source.get_ohlcv(symbol, "15m", limit=1)
                    if candles_15m:
                        last_candle = candles_15m[-1]
                        await position_tracker.update_with_candle(symbol, last_candle)

                        # –û–±–Ω–æ–≤–ª—è–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π
                        active_positions = []
                        for pos in position_tracker.positions.get(symbol, []):
                            if pos.status.value in ["PENDING", "OPEN"]:
                                active_positions.append(pos.direction)

                        if active_positions:
                            active_signals_per_symbol[symbol] = set(active_positions)
                        elif symbol in active_signals_per_symbol:
                            del active_signals_per_symbol[symbol]

                except Exception as e:
                    print(f"  √¢≈°¬† Failed to update positions: {e}")

                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å–∏–º–≤–æ–ª–∞–º–∏
                await asyncio.sleep(0.1)

            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã
            all_active_signals = [s for s in all_active_signals
                                  if s.symbol in active_signals_per_symbol]

            # ---------------------------------------
            # 10) –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¶–ò–ö–õ–ê
            # ---------------------------------------
            total_time = time.time() - start

            print("\n" + "=" * 50)
            print(f"üìä CYCLE #{cycle_count} STATISTICS:")
            print(f"‚Ä¢ Total time: {total_time:.2f} sec")
            print(f"‚Ä¢ Signals found: {total_signals}")
            print(f"‚Ä¢ After validation: {validated_signals}")
            print(f"‚Ä¢ Confluence filtered: {confluence_filtered}")
            print(f"‚Ä¢ Performance filtered: {performance_filtered}")
            print(f"‚Ä¢ Unique cached: {deduplicator.get_stats()["active_zones"]}")
            print(f"‚Ä¢ Active symbols: {len(active_signals_per_symbol)}")

            if signals_by_chain:
                print("\nüîó Signals by chain:")
                for chain_id, count in sorted(signals_by_chain.items()):
                    print(f"  ‚Ä¢ {chain_id}: {count}")

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç—Ä–µ–∫–µ—Ä—É
            tracker_stats = position_tracker.get_stats()

            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
            signal_publisher.update_stats_from_tracker(tracker_stats)

            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∑–∞–∫—Ä–µ–ø–µ
            signal_publisher.active_positions.clear()
            for sym, positions in position_tracker.positions.items():
                for pos in positions:
                    if pos.status.value == "OPEN":
                        signal_publisher.add_active_position(sym, str(pos.direction), pos.entry)

            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–∫—Ä–µ–ø
            await signal_publisher.update_pinned_stats()

            print(f"\nüìà POSITION TRACKER:")
            print(f"‚Ä¢ Total: {tracker_stats['total']}")
            print(f"‚Ä¢ Pending: {tracker_stats['pending']}")
            print(f"‚Ä¢ Open: {tracker_stats['open']}")
            print(f"‚Ä¢ Closed TP: {tracker_stats['closed_tp']}")
            print(f"‚Ä¢ Closed SL: {tracker_stats['closed_sl']}")
            print(f"‚Ä¢ Cancelled: {tracker_stats['cancelled']}")

            # Win rate –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏
            total_closed = tracker_stats['closed_tp'] + tracker_stats['closed_sl']
            if total_closed > 0:
                win_rate = (tracker_stats['closed_tp'] / total_closed) * 100
                print(f"‚Ä¢ Win Rate: {win_rate:.1f}%")

            # –†–µ–π—Ç–∏–Ω–≥ —Ü–µ–ø–æ—á–µ–∫ –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if cycle_count % 50 == 0:
                rankings = performance_optimizer.get_chain_ranking()
                if rankings:
                    print("\nüèÜ Chain Performance Rankings:")
                    for i, (chain_id, score) in enumerate(rankings[:5], 1):
                        print(f"  {i}. {chain_id}: {score:.3f}")

            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ Telegram
            if validated_signals > 0 or cycle_count % 20 == 0:
                stats_msg = (
                    f"üìä Cycle #{cycle_count}\n"
                    f"Time: {total_time:.1f}s\n"
                    f"Signals: {validated_signals}\n"
                    f"Filtered: {confluence_filtered + performance_filtered}\n"
                    f"Positions: {tracker_stats['open']} open, {tracker_stats['pending']} pending\n"
                    f"Results: {tracker_stats['closed_tp']}‚úÖ / {tracker_stats['closed_sl']}‚ùå"
                )

                if total_closed > 10:
                    stats_msg += f"\nWin Rate: {win_rate:.1f}%"

                await log(stats_msg, to_telegram=True)

            print("=" * 50)

            # ---------------------------------------
            # 11) –û–ß–ò–°–¢–ö–ê –°–¢–ê–†–´–• –î–ê–ù–ù–´–•
            # ---------------------------------------
            if cycle_count % 100 == 0 and deduplicator.get_stats()["active_zones"] > 500:
                print("üßπ Clearing old cache...")
                deduplicator.cleanup()

            if cycle_count % POSITION_CLEANUP_INTERVAL == 0:
                removed = position_tracker.cleanup_old_positions()
                if removed > 0:
                    print(f"üßπ Removed {removed} old positions")

            # ---------------------------------------
            # 12) –û–ñ–ò–î–ê–ù–ò–ï –°–õ–ï–î–£–Æ–©–ï–ì–û –¶–ò–ö–õ–ê
            # ---------------------------------------
            next_time = start + LOOP_INTERVAL
            now = time.time()

            if now < next_time:
                wait = next_time - now
                print(f"\n‚è≥ Next scan in {int(wait)} seconds...")
                await asyncio.sleep(wait)
            else:
                print("\n√¢≈°¬† Scan took longer than interval, starting immediately...")

    except KeyboardInterrupt:
        print("\nüõë Stopping bot (KeyboardInterrupt)")

    except Exception as e:
        print(f"\n‚ùå CRITICAL ERROR: {e}")
        await log(f"‚ùå CRITICAL ERROR: {e}", to_telegram=True)
        import traceback
        print(traceback.format_exc())

    finally:
        try:
            await source.close()
            print("‚úÖ Binance connection closed")
        except:
            pass

        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n" + "=" * 50)
        print("üìä FINAL STATISTICS:")
        final_stats = position_tracker.get_stats()
        print(f"‚Ä¢ Total positions: {final_stats['total']}")
        print(f"‚Ä¢ Win rate: {final_stats['closed_tp']}/{final_stats['total']}")
        print(f"‚Ä¢ Total cycles: {cycle_count}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ü–µ–ø–æ—á–∫–∞–º
        if final_stats['by_chain']:
            print("\nüîó Performance by chain:")
            for chain_id, stats in final_stats['by_chain'].items():
                if stats['total'] > 0:
                    wins = stats.get('tp', 0)
                    losses = stats.get('sl', 0)
                    total = wins + losses
                    if total > 0:
                        wr = (wins / total) * 100
                        print(f"  ‚Ä¢ {chain_id}: {wins}‚úÖ/{losses}‚ùå (WR: {wr:.1f}%)")

        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ —Ü–µ–ø–æ—á–µ–∫
        rankings = performance_optimizer.get_chain_ranking()
        if rankings:
            print("\nüèÜ Final Chain Rankings:")
            for i, (chain_id, score) in enumerate(rankings[:5], 1):
                print(f"  {i}. {chain_id}: Score {score:.3f}")

        print("=" * 50)


if __name__ == "__main__":
    asyncio.run(main())